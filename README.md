This evaluation pipeline is part of the dissertation. "Exploring Grammatical Constraints in Large Language Models". 
It is forked from: babylm/evaluation-pipeline-2024

To start the evalution, run the respective files 'evaluation_model.py'. 
All results are saved in the folder: 'results'.